replicas: 3

deployment:
  # if enabled:false this will create a cronjob rather than
  # a deployment.
  enabled: false

cronJob:
  # If set to {} defaults to 23h
  period: {}
  # If set to {} defaults to "" (scanning all bugs)
  bugs: {}
  delay: {}

startUpDelay: 5
backoffDuration: 5

podNetworkPolicy:
  enabled: true

podPriorityClass:
      # If .Values.global.podPriorityClass.enabled and spec is {}
  # defaults to
  #   globalDefault: false
  #   value: 400
  #   preemptionPolicy: Never
  spec: {}

extraConfigs: {}
extraSecrets: {}

# Sets logging level for shell scripts as well as jar
debug: false

podDisruptionBudget: {}
  #    Warning :  this won't be applied unless the replicas
  #               values are >= 2
  # minAvailable: 1

selfAntiAffinity:
  #     You can set selfAntiAffinity to {} in order to skip
  #     all affinity declarations in the statefulset
  soft: true
  weight: 100

image:
  initContainer:
    pullPolicy: "IfNotPresent"
    registry: {}
    registryPort: {}
    name: "postgres"
    # Alpine images for init container to reduce
    # overal resource strain with Image size: 28MBs
    tag: "11.5-alpine"

    securityContext:
      runAsUser: 65534
      runAsGroup: 65534
      privileged: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
        add:
          - SYS_TIME
          - NET_ADMIN

    resources:
      limits:
        memory: "35Mi"
        cpu: "100m"
      requests:
        memory: "25Mi"
        cpu: "100m"

  mainContainer:
    pullPolicy: "IfNotPresent"
    registry: {}
    registryPort: {}
    name: "eclipse/steady-patch-lib-analyzer"
    #     Footprint:
    #     - size: 140.48MB
    tag: "3.2.0-SNAPSHOT-jib"

    securityContext:
      runAsUser: 65534
      runAsGroup: 65534
      privileged: false
      readOnlyRootFilesystem: false
      capabilities:
        drop:
          - ALL
        add:
          - DAC_OVERRIDE
          - SYS_TIME
          - NET_ADMIN

    resources:
      limits:
        memory: "4Gi"
        cpu: "1000m"
      requests:
        memory: "1Gi"
        cpu: "500m"


# RWO is possible but mounting an nfs with RWM
# allows patcheval caches to share the same data
# thus allowing for a gain in performance
persistentVolume: {}
  # storage: "1Gi"
  # mountPath: /patcheval-data
  # nfs:
  #     #     #   #   nfs can be set to {} and it will automatically be
  #   #   updated as to the accessMode
  #   server: ::
  #   path: /share

livenessProbe:
  # Worst case scenario time before container is considered unready by k8s :
  # initialDelaySeconds + ((periodSeconds + timeoutSeconds) * successThreshold)
  # = 145s ~= 2.5min
  enabled: true
  initialDelaySeconds: 30
  periodSeconds: 20
  timeoutSeconds: 5
  failureThreshold: 5
