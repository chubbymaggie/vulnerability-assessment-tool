# Kibana deployment meant to link up with elasticsearch to provide a
# graphical option to analyze log data

kibana:
  enabled: true
  # Suggestion : ~= elasticsearch cluster members / 2
  replicas: 1

  path: /monitoring/kibana
  extraConfigs: {}
  debug: false
  # soft anti affinity towards sharing nodes with kibana pods
  # recommended to garantee uptime for services
  selfAntiAffinity: {}
    # soft: true
    # weight: 100

  # soft affinity towards sharing nodes with elasticsearch pods
  # recommended to garantee uptime for services
  elasticsearchAffinity: {}
    # soft: true
    # weight: 100

  # Pod disruption budget for kibana deployment makes sure during
  # changes at least {.Values.kibana.minAvailable} kibana pod is available
  podDisruptionBudget: {}
    # minAvailable: 1

  serverHost: "0.0.0.0"

  plugins:
    enabled: false
    # reset: true
    # values:
    #   - logtrail,0.1.31,https://github.com/sivasamyk/logtrail/releases/download/v0.1.31/logtrail-7.3.1-0.1.31.zip

  persistentVolume:
    enabled: false
    storage: {}

  securityContext: {}
    # default security context
    # enabled: true
    # allowPrivilegeEscalation: false
    # runAsUser: 1000

  image:
    pullPolicy: "IfNotPresent"
    registry: {}
    registryPort: {}
    # Image size : 359MB
    name: "kibana"
    tag: "7.3.1"

    resources: {}
      # limits:
      #   memory: "2G"
      #   cpu: "2000m"
      # requests:
      #   memory: "1G"
      #   cpu: "1000m"

  readinessProbe:
    # Worst case scenario time before container is considered unready by k8s :
    # initialDelaySeconds + ((periodSeconds + timeoutSeconds) * successThreshold)
    # = 80s ~= 1.4min
    enabled: true
    initialDelaySeconds: 15
    failureThreshold: 3
    periodSeconds: 10
    timeoutSeconds: 5

  livenessProbe:
    # Worst case scenario time before container is considered unready by k8s :
    # initialDelaySeconds + ((periodSeconds + timeoutSeconds) * successThreshold)
    # = 95s ~= 1.5min
    enabled: true
    initialDelaySeconds: 30
    failureThreshold: 3
    periodSeconds: 10
    timeoutSeconds: 5


elasticsearch:
  debug: false
  retention: {}
    # max_size: "100GB"
    # max_age: "180d"
    # min_age: "90d"

  clusterName: "elasticsearch"
  nodeGroup: "master"
  extraConfigs: {}
  # Suggestion : >= 3
  replicas: 3

  roles:
    master: "true"
    ingest: "true"
    data: "true"

  # Java heap size for elasticsearch
  # Xmx : maximum heap size
  # Xms : minimum heap size
  # Elasticsearch's recommendation:
  #     Xmx, Xms <= 50% RAM available on server
  #     Xmx, Xms <= threshold JVM uses for compressed objects
  #                 pointers (compressed oops) ~= 32 GB
  #                 can be verified looking at elastic logs
  #     Xmx, Xms <= threshold JVM uses for zero-based compressed
  #                 oops ~= 26Gb on most system
  esJavaOpts: "-Xmx1g -Xms1g"
  networkHost: "0.0.0.0"

  # Since elasticsearch uses mmapfs directory to store its indices
  # increases it to avoid out of memory exceptions
  sysctlVmMaxMapCount: 262144

  # soft Anti affinity towards sharing pods with other
  # elasticsearch cluster members
  selfAntiAffinity: 100

  # Allows for automated rolling updates
  updateStrategy: RollingUpdate
  # Allows independent termination and creation of pods
  podManagementPolicy: "Parallel"
  # Allows pods to live a certain period after termination
  terminationGracePeriodSeconds: 120
  clusterHealthCheckParams: "wait_for_status=green&timeout=1s"
  podDisruptionBudget:
    maxUnavailable: 1

  image:
    initContainer:
      pullPolicy: "IfNotPresent"
      registry: {}
      registryPort: {}
      # busybox images for init container to reduce
      # overal resource strain with Image size: 763KB
      name: "busybox"
      tag: "1.31.0"

      resources: {}
        # limits:
        #   cpu: "25m"
        #   memory: "150Mi"
        # requests:
        #   cpu: "25m"
        #   memory: "128Mi"

      securityContext:
        privileged: true
        runAsUser: 0

    mainContainer:
      pullPolicy: "IfNotPresent"
      registry: {}
      registryPort: {}
      # Image size : 405MB
      name: "elasticsearch"
      tag: "7.3.1"

      resources: {}
        # limits:
        #   cpu: "1000m"
        #   memory: "2Gi"
        # requests:
        #   cpu: "100m"
        #   memory: "1Gi"

      readinessProbe:
        # Worst case scenario time before container is considered unready by k8s :
        # initialDelaySeconds + ((periodSeconds + timeoutSeconds) * successThreshold)
        # = 64s ~= 1min
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 3
        timeoutSeconds: 5

      securityContext:
        capabilities:
          drop:
          - ALL
        # readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000

    sidecarContainer:
      pullPolicy: "IfNotPresent"
      registry: {}
      registryPort: {}
      # Image size : 405MB
      name: "elasticsearch"
      tag: "7.3.1"

      resources: {}
        # limits:
        #   cpu: "50m"
        #   memory: "150Mi"
        # requests:
        #   cpu: "25m"
        #   memory: "128Mi"

  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    resources:
      requests:
        storage: "10Gi"
